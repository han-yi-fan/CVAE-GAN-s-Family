{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"CVAE-WGAN-GP.ipynb（副本）","provenance":[{"file_id":"12AjrOZhgNuzXD-xC_WWiRD5Tl61fwQ2E","timestamp":1605435656379}],"collapsed_sections":[],"authorship_tag":"ABX9TyONP5HwO48eLBNM1fvM+uu8"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wja_6s6s6vbi","executionInfo":{"status":"ok","timestamp":1606264529666,"user_tz":-480,"elapsed":1319,"user":{"displayName":"韩轶凡","photoUrl":"","userId":"03071036090357054572"}},"outputId":"1969e440-5ed4-469b-d43e-1c00ecdf2503"},"source":["!/opt/bin/nvidia-smi\n","\n","!rm -rf /content/sample_data\n","\n","!rm -rf /content/img_CVAE-WGANGP"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Wed Nov 25 00:35:29 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   73C    P0    34W /  70W |   1179MiB / 15079MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"82k1f_YN6_lg","executionInfo":{"status":"ok","timestamp":1606263113745,"user_tz":-480,"elapsed":4862,"user":{"displayName":"韩轶凡","photoUrl":"","userId":"03071036090357054572"}}},"source":["from __future__ import print_function\n","import argparse\n","import os,time\n","import random\n","import math\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.backends.cudnn as cudnn\n","import torch.optim as optim\n","import torch.utils.data\n","import torchvision.datasets as dset\n","import torchvision.transforms as transforms\n","from torchvision.utils import save_image\n","from torchvision.utils import make_grid\n","import torch.nn.functional as F\n","\n","import imageio\n","import matplotlib.pyplot as plt"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"h9a1gMGC7Rag","executionInfo":{"status":"ok","timestamp":1606264521455,"user_tz":-480,"elapsed":1314,"user":{"displayName":"韩轶凡","photoUrl":"","userId":"03071036090357054572"}}},"source":["class VAE(nn.Module):\n","    def __init__(self):\n","\n","        super(VAE, self).__init__()\n","        \n","        self.encoder_conv = nn.Sequential(\n","            nn.Conv2d(1,16,kernel_size=3,stride=2,padding=1),\n","            \n","            nn.LeakyReLU(0.2,inplace=True),\n","            nn.BatchNorm2d(16),\n","            nn.Conv2d(16,32,kernel_size=3,stride=2,padding=1),\n","            \n","            nn.LeakyReLU(0.2,inplace=True),\n","            nn.BatchNorm2d(32),\n","            nn.Conv2d(32,32,kernel_size=3,stride=1,padding=1),\n","            \n","            nn.LeakyReLU(0.2,inplace=True),\n","            nn.BatchNorm2d(32),\n","        )\n","\n","        self.encoder_fc1=nn.Linear(32*7*7,nz)\n","        self.encoder_fc2=nn.Linear(32*7*7,nz)\n","        self.Sigmoid = nn.Sigmoid()\n","        self.decoder_fc = nn.Linear(nz+10,32 * 7 * 7)\n","        self.decoder_deconv = nn.Sequential(\n","            nn.ConvTranspose2d(32, 16, 4, 2, 1),\n","            nn.LeakyReLU(0.2,inplace=True),\n","            nn.ConvTranspose2d(16, 1, 4, 2, 1),\n","            nn.Tanh(),\n","        )\n","\n","    def noise_reparameterize(self,mean,logvar):\n","        eps = torch.randn(mean.shape).to(device)\n","        z = mean + eps * torch.exp(logvar)\n","        return z\n","\n","    def encoder(self,x):\n","        out1, out2 = self.encoder_conv(x), self.encoder_conv(x)\n","        mean = self.encoder_fc1(out1.view(out1.shape[0], -1))\n","        logstd = self.encoder_fc2(out2.view(out2.shape[0], -1))\n","        z = self.noise_reparameterize(mean, logstd)\n","        return z,mean,logstd\n","\n","    def decoder(self,z):\n","        out3 = self.decoder_fc(z)\n","        out3 = out3.view(out3.shape[0], 32, 7, 7)\n","        out3 = self.decoder_deconv(out3)\n","        return out3\n","\n","    def forward(self, x):\n","        z = self.encoder(x)\n","        output = self.decoder(z)\n","        return output"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"gp57T8X4Kw8b","executionInfo":{"status":"ok","timestamp":1606263120617,"user_tz":-480,"elapsed":1323,"user":{"displayName":"韩轶凡","photoUrl":"","userId":"03071036090357054572"}}},"source":["class Classifier(nn.Module):\n","    def __init__(self):\n","        super(Classifier, self).__init__()\n","        self.dis = nn.Sequential(\n","            nn.Conv2d(1, 32, 3, stride=1, padding=1),\n","            nn.BatchNorm2d(32),\n","            nn.LeakyReLU(0.2, True),\n","            nn.MaxPool2d((2, 2)),\n","            nn.Conv2d(32, 64, 3, stride=1, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.LeakyReLU(0.2, True),\n","            nn.MaxPool2d((2, 2)),\n","        )\n","        self.fc = nn.Sequential(\n","            nn.Linear(7 * 7 * 64, 1024),\n","            nn.LeakyReLU(0.2, True),\n","            nn.Linear(1024, 10),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, input):\n","        x = self.dis(input)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","        return x.squeeze(1)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"2oODeb6lKuzK","executionInfo":{"status":"ok","timestamp":1606263123317,"user_tz":-480,"elapsed":1341,"user":{"displayName":"韩轶凡","photoUrl":"","userId":"03071036090357054572"}}},"source":["class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","        self.dis = nn.Sequential(\n","            nn.Linear(784, 256),  # 输入特征数为784，输出为256\n","            nn.LeakyReLU(0.2),  # 进行非线性映射\n","            nn.Linear(256, 256),  # 进行一个线性映射\n","            nn.LeakyReLU(0.2),\n","            nn.Linear(256, 1),\n","            nn.Sigmoid()  # 也是一个激活函数，二分类问题中，\n","        )\n","\n","    def forward(self, x):\n","        x = x.view(x.size(0), -1)\n","        x = self.dis(x)\n","        return x"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ro2BSkC_7WfX","executionInfo":{"status":"ok","timestamp":1606263126673,"user_tz":-480,"elapsed":1346,"user":{"displayName":"韩轶凡","photoUrl":"","userId":"03071036090357054572"}}},"source":["def loss_function(recon_x,x,mean,logstd):\n","    # BCE = F.binary_cross_entropy(recon_x,x,reduction='sum')\n","    MSE = MSECriterion(recon_x,x)\n","    # 因为var是标准差的自然对数，先求自然对数然后平方转换成方差\n","    var = torch.pow(torch.exp(logstd),2)\n","    KLD = -0.5 * torch.sum(1+torch.log(var)-torch.pow(mean,2)-var)\n","    return MSE+KLD"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R352_2Sf7as0","executionInfo":{"status":"ok","timestamp":1606265438245,"user_tz":-480,"elapsed":904052,"user":{"displayName":"韩轶凡","photoUrl":"","userId":"03071036090357054572"}},"outputId":"046cac46-e8fc-44a3-e150-ca87a70bb156"},"source":["if __name__ == '__main__':\n","    batchSize = 128\n","    imageSize = 28\n","    nz = 100\n","    nepoch = 20\n","    lambda_ = 10\n","    \n","    if not os.path.exists('./img_CVAE-WGANGP'):\n","        os.mkdir('./img_CVAE-WGANGP')\n","\n","    # random.seed(88)\n","    # torch.manual_seed(88)\n","\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","    cudnn.benchmark = True\n","\n","    dataset = dset.MNIST(root='./data',\n","                train=True,\n","                transform=transforms.Compose([transforms.ToTensor()]),\n","                download=True\n","                )\n","\n","    dataloader = torch.utils.data.DataLoader(dataset,\n","                          batch_size=batchSize,\n","                          shuffle=True)\n","\n","    print(\"=====> Initialization\")\n","    vae = VAE().to(device)\n","    # vae.load_state_dict(torch.load('./VAE-WGANGP-VAE_v2.pth'))\n","\n","    # discriminator\n","    D = Discriminator().to(device)\n","    # D.load_state_dict(torch.load('./VAE-GAN-Discriminator.pth'))\n","\n","    # Classifier\n","    C = Classifier().to(device)\n","    # C.load_state_dict(torch.load('./CVAE-GAN-Classifier.pth'))\n","    \n","    criterion = nn.BCELoss().to(device)\n","    MSECriterion = nn.MSELoss().to(device)\n","\n","    optimizerD = optim.Adam(D.parameters(), lr=0.0002,betas=(0.5, 0.999))\n","    optimizerC = optim.Adam(C.parameters(), lr=0.0002,betas=(0.5, 0.999))\n","    optimizerVAE = optim.Adam(vae.parameters(), lr=0.0002,betas=(0.5, 0.999))\n","\n","    # sample_label\n","    s_label = []\n","    for i in [1,8,0,9,4,0,1,0,5,3]:\n","      s_label += [ i for _ in range(8)]\n","    specific_label = torch.zeros((80, 10)).cuda()\n","    specific_label[torch.arange(80), s_label] = 1\n","\n","    print(\"=====> Begin training\")\n","    \n","    start_time = time.time()\n","    for epoch in range(nepoch):\n","\n","        if(epoch%5==0): lambda_ -= 1\n","        \n","        epoch_start_time = time.time()\n","\n","        for i, (data,label) in enumerate(dataloader, 0):\n","            \n","            for n in range(1):\n","              \n","                # data processing\n","                data = data.to(device)\n","                label = label.to(device)\n","                label_onehot = torch.zeros((data.shape[0], 10)).to(device)\n","                label_onehot[torch.arange(data.shape[0]), label] = 1\n","                batch_size = data.shape[0]\n","\n","                # training C with real\n","                C.zero_grad()\n","                \n","                output = C(data)\n","                real_label = label_onehot.to(device)\n","                errC = criterion(output, real_label)\n","                \n","                errC.backward()\n","                optimizerC.step()\n","                \n","                ###################################################################\n","                # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n","                ###################################################################\n","\n","                # train with real\n","\n","                D.zero_grad()\n","\n","                real_out = D(data)\n","\n","                real_label = torch.ones(batch_size).to(device)  \n","                fake_label = torch.zeros(batch_size).to(device)  \n","\n","                real_data_score = real_out.mean().item()\n","\n","                # train with fake, taking the noise vector z as the input of D network\n","                z = torch.randn(batch_size, nz+10).to(device)  # 标准正态分布（均值为0，方差为1，即高斯白噪声）\n","                fake_data = vae.decoder(z)\n","                fake_out = D(fake_data)\n","\n","                # fake_data_score用来输出查看的，是虚假照片的评分，0最假，1为真\n","                fake_data_score = fake_out.mean().item()\n","\n","                alpha = torch.rand((batch_size, 1, 1, 1)).to(device)\n","                x_hat = alpha * data + (1 - alpha) * fake_data\n","\n","                pred_hat = D(x_hat)\n","\n","                gradients = \\\n","                    torch.autograd.grad(outputs=pred_hat, inputs=x_hat, grad_outputs=torch.ones(pred_hat.size()).to(device),\n","                                        create_graph=True, retain_graph=True, only_inputs=True)[0]\n","                gradient_penalty = lambda_ * ((gradients.view(gradients.size()[0], -1).norm(2, 1) - 1) ** 2).mean()\n","\n","                d_loss = torch.mean(fake_out) - torch.mean(real_out) + gradient_penalty\n","                \n","                d_loss.backward()\n","                optimizerD.step()\n","\n","            for _ in range(3):\n","              ###################################################\n","              # (2) Update G network which is the decoder of VAE\n","              ###################################################\n","              z,mean,logstd = vae.encoder(data)\n","              z = torch.cat([z,label_onehot],1)\n","              \n","              vae.zero_grad()\n","              \n","              recon_data = vae.decoder(z)\n","              vae_loss = loss_function(recon_data,data,mean,logstd)\n","\n","              vae_loss.backward(retain_graph=True)\n","              optimizerVAE.step()\n","              \n","              ###############################################\n","              # (3) Update G network: maximize log(D(G(z)))\n","              ###############################################\n","              z,mean,logstd = vae.encoder(data)\n","              z = torch.cat([z,label_onehot],1)\n","      \n","              vae.zero_grad()\n","              \n","              recon_data = vae.decoder(z)\n","              # real_label = torch.ones(batch_size).to(device)  \n","              output = D(recon_data)\n","              errVAE = torch.mean(-output)\n","\n","              errVAE.backward()\n","              optimizerVAE.step()\n","\n","              ###############################################\n","              # (4) Update C network\n","              ###############################################   \n","              z,mean,logstd = vae.encoder(data)\n","              z = torch.cat([z,label_onehot],1)\n","              \n","\n","              vae.zero_grad()\n","\n","              recon_data = vae.decoder(z) \n","              output = C(recon_data)\n","              real_label = label_onehot\n","              c_loss = criterion(output, real_label)\n","          \n","              c_loss.backward()\n","              optimizerC.step()\n","\n","        epoch_end_time = time.time()\n","        per_epoch_ptime = epoch_end_time - epoch_start_time\n","        print('[%d/%d] time: %.2f real_score: %.4f fake_score: %.4f d_loss: %.4f g_loss: %.4f'\n","              % (epoch+1, nepoch, per_epoch_ptime,real_data_score,fake_data_score,d_loss,vae_loss))\n","    \n","        sample = torch.randn(80, nz).to(device)\n","        sample = torch.cat([sample,specific_label],1)\n","        output = vae.decoder(sample)\n","        fake_images = make_grid(output.cpu(), nrow=8, normalize=True).detach()\n","        save_image(fake_images, './img_CVAE-WGANGP/fake_images-{}.png'.format(epoch + 1))\n","\n","    end_time = time.time()\n","    total_time = end_time - start_time\n","    print(\"total time: %.2f \" % total_time )\n","\n","images = []\n","for e in range(nepoch):\n","    img_name = './img_CVAE-WGANGP/fake_images-' + str(e+1) + '.png'\n","    images.append(imageio.imread(img_name))\n","imageio.mimsave('./generation_animation.gif', images, fps=2)\n","\n","# torch.save(vae.state_dict(), './CVAE-WGANGP-VAE.pth')\n","# torch.save(D.state_dict(),'./CVAE-WGANGP-Discriminator.pth')"],"execution_count":10,"outputs":[{"output_type":"stream","text":["=====> Initialization\n","=====> Begin training\n","[1/20] time: 46.47 real_score: 0.2637 fake_score: 0.6816 d_loss: 5.4848 g_loss: 11.9961\n","[2/20] time: 45.13 real_score: 0.4752 fake_score: 0.6746 d_loss: 5.7559 g_loss: 6.4040\n","[3/20] time: 44.61 real_score: 0.3732 fake_score: 0.6650 d_loss: 5.3472 g_loss: 2.6756\n","[4/20] time: 44.64 real_score: 0.2611 fake_score: 0.7916 d_loss: 4.6252 g_loss: 0.7363\n","[5/20] time: 44.57 real_score: 0.2431 fake_score: 0.6731 d_loss: 3.9366 g_loss: 1.0879\n","[6/20] time: 45.20 real_score: 0.2176 fake_score: 0.7476 d_loss: 4.0657 g_loss: 0.2394\n","[7/20] time: 45.26 real_score: 0.1747 fake_score: 0.7814 d_loss: 3.4929 g_loss: 0.2703\n","[8/20] time: 45.18 real_score: 0.1092 fake_score: 0.9075 d_loss: 3.7502 g_loss: 0.2099\n","[9/20] time: 44.89 real_score: 0.2056 fake_score: 0.8765 d_loss: 3.4065 g_loss: 0.2232\n","[10/20] time: 45.74 real_score: 0.2065 fake_score: 0.8431 d_loss: 3.1993 g_loss: 0.0850\n","[11/20] time: 45.23 real_score: 0.2209 fake_score: 0.8206 d_loss: 2.9362 g_loss: 0.3233\n","[12/20] time: 45.36 real_score: 0.2053 fake_score: 0.8590 d_loss: 3.0797 g_loss: 0.0666\n","[13/20] time: 45.16 real_score: 0.2217 fake_score: 0.7917 d_loss: 2.4221 g_loss: 0.0578\n","[14/20] time: 44.78 real_score: 0.2112 fake_score: 0.7422 d_loss: 2.5587 g_loss: 0.0653\n","[15/20] time: 45.11 real_score: 0.2054 fake_score: 0.7331 d_loss: 2.6486 g_loss: 0.0571\n","[16/20] time: 45.86 real_score: 0.2095 fake_score: 0.7710 d_loss: 2.6239 g_loss: 0.0605\n","[17/20] time: 45.75 real_score: 0.1756 fake_score: 0.7175 d_loss: 2.3228 g_loss: 0.0601\n","[18/20] time: 45.24 real_score: 0.2082 fake_score: 0.7110 d_loss: 1.9304 g_loss: 0.0630\n","[19/20] time: 44.13 real_score: 0.1868 fake_score: 0.7290 d_loss: 2.1571 g_loss: 0.0656\n","[20/20] time: 43.25 real_score: 0.1710 fake_score: 0.7619 d_loss: 2.2778 g_loss: 0.0642\n","total time: 902.19 \n"],"name":"stdout"}]}]}