{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"new_CVAE-WGAN-GP.ipynb","provenance":[{"file_id":"12AjrOZhgNuzXD-xC_WWiRD5Tl61fwQ2E","timestamp":1605435656379}],"collapsed_sections":[],"mount_file_id":"1MJ-kuDKW-MGXNC5e4gEMVb8zncKZgcBe","authorship_tag":"ABX9TyNHCq5kmqwKWe+T1IoFwcv0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Wja_6s6s6vbi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606871431521,"user_tz":-480,"elapsed":1810,"user":{"displayName":"韩轶凡","photoUrl":"","userId":"03071036090357054572"}},"outputId":"526ffd2c-0af4-4309-8e22-c5d315ca7369"},"source":["!/opt/bin/nvidia-smi\n","\n","!rm -rf /content/sample_data\n","\n","!rm -rf /content/img_CVAE-WGANGP"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Wed Dec  2 01:10:31 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   47C    P0    28W /  70W |   2631MiB / 15079MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"82k1f_YN6_lg","executionInfo":{"status":"ok","timestamp":1606871431523,"user_tz":-480,"elapsed":1148,"user":{"displayName":"韩轶凡","photoUrl":"","userId":"03071036090357054572"}}},"source":["from __future__ import print_function\n","import argparse\n","import os,time\n","import random\n","import math\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.backends.cudnn as cudnn\n","import torch.optim as optim\n","import torch.utils.data\n","import torchvision.datasets as dset\n","import torchvision.transforms as transforms\n","from torchvision.utils import save_image\n","from torchvision.utils import make_grid\n","import torch.nn.functional as F\n","import scipy.stats\n","import imageio\n","import matplotlib.pyplot as plt"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"h9a1gMGC7Rag","executionInfo":{"status":"ok","timestamp":1606871435608,"user_tz":-480,"elapsed":4279,"user":{"displayName":"韩轶凡","photoUrl":"","userId":"03071036090357054572"}}},"source":["class VAE(nn.Module):\n","    def __init__(self):\n","\n","        super(VAE, self).__init__()\n","        \n","        self.encoder_conv = nn.Sequential(\n","            nn.Conv2d(3,16,kernel_size=5,stride=2,padding=1),\n","            nn.BatchNorm2d(16),\n","            nn.LeakyReLU(0.2,inplace=True),\n","            nn.Conv2d(16,64,kernel_size=5,stride=2,padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.LeakyReLU(0.2,inplace=True),\n","            nn.Conv2d(64,32,kernel_size=5,stride=1,padding=1),\n","            nn.BatchNorm2d(32),\n","            nn.LeakyReLU(0.2,inplace=True),\n","        )\n","\n","        self.encoder_fc1=nn.Linear(32*25,nz)\n","        self.encoder_fc2=nn.Linear(32*25,nz)\n","        self.Sigmoid = nn.Sigmoid()\n","       \n","        self.decoder_fc=nn.Linear(nz+10,3 * 64 * 64)\n","        self.br=nn.Sequential(\n","            nn.BatchNorm2d(3),\n","            nn.ReLU(True),\n","        )\n","        self.gen = nn.Sequential(\n","            nn.Conv2d(3,64,5,stride=1,padding=2),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(True),\n","\n","            nn.Conv2d(64,32,5,stride=1,padding=2),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(True),\n","\n","            nn.Conv2d(32,3,4,stride=2,padding=1),\n","            nn.Tanh(),\n","        )\n","    \n","    def decoder(self,z):\n","        x = self.decoder_fc(z)\n","        x=x.view(x.shape[0],3,64,64)\n","        x=self.br(x)\n","        x = nn.functional.dropout(x, p=0.5, training=self.training)\n","        x=self.gen(x)\n","        return x\n","\n","    def noise_reparameterize(self,mean,logvar):\n","        eps = torch.randn(mean.shape).to(device)\n","        z = mean + eps * torch.exp(logvar)\n","        return z\n","\n","    def encoder(self,x):\n","        out1, out2 = self.encoder_conv(x), self.encoder_conv(x)\n","        mean = self.encoder_fc1(out1.view(out1.shape[0], -1))\n","        logstd = self.encoder_fc2(out2.view(out2.shape[0], -1))\n","        z = self.noise_reparameterize(mean, logstd)\n","        return z,mean,logstd\n","\n","    def forward(self, x):\n","        z = self.encoder(x)\n","        output = self.decoder(z)\n","        return output"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"SQkWtBQ57UQq","executionInfo":{"status":"ok","timestamp":1606871435610,"user_tz":-480,"elapsed":2309,"user":{"displayName":"韩轶凡","photoUrl":"","userId":"03071036090357054572"}}},"source":["class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","        self.dis = nn.Sequential(\n","            nn.Conv2d(3,32,5,stride=1,padding=1),\n","            nn.LeakyReLU(0.2,True),\n","            nn.MaxPool2d((2,2)),\n","\n","            nn.Conv2d(32,64,5,stride=1,padding=1),\n","            nn.LeakyReLU(0.2,True),\n","            nn.MaxPool2d((2,2)),\n","        )\n","        self.fc = nn.Sequential(\n","            # nn.Linear(8*8*64,1024),\n","            nn.Linear(2304,1024),\n","            nn.LeakyReLU(0.2,True),\n","            nn.Linear(1024,1),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        x = self.dis(x)\n","        x=x.view(x.size(0),-1)\n","        x=self.fc(x)\n","        x = x.view(x.size(0))\n","        return x"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"d3sZBBZlrSoq","executionInfo":{"status":"ok","timestamp":1606871436175,"user_tz":-480,"elapsed":1717,"user":{"displayName":"韩轶凡","photoUrl":"","userId":"03071036090357054572"}}},"source":["class Classifier(nn.Module):\n","    def __init__(self):\n","        super(Classifier, self).__init__()\n","        self.dis = nn.Sequential(\n","            nn.Conv2d(3, 32, 5, stride=1, padding=1),\n","            nn.LeakyReLU(0.2, True),\n","            nn.MaxPool2d((2, 2)),\n","\n","            nn.Conv2d(32, 64, 5, stride=1, padding=1),\n","            nn.LeakyReLU(0.2, True),\n","            nn.MaxPool2d((2, 2)),\n","        )\n","        self.fc = nn.Sequential(\n","            # nn.Linear(8 * 8 * 64, 1024),\n","            nn.Linear(2304, 1024),\n","            nn.LeakyReLU(0.2, True),\n","            nn.Linear(1024, 10),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, input):\n","        x = self.dis(input)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","        return x.squeeze(1)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ro2BSkC_7WfX","executionInfo":{"status":"ok","timestamp":1606871436764,"user_tz":-480,"elapsed":1275,"user":{"displayName":"韩轶凡","photoUrl":"","userId":"03071036090357054572"}}},"source":["def loss_function(recon_x,x,mean,logstd):\n","    # BCE = F.binary_cross_entropy(recon_x,x,reduction='sum')\n","    MSE = MSECriterion(recon_x,x)\n","    # 因为var是标准差的自然对数，先求自然对数然后平方转换成方差\n","    var = torch.pow(torch.exp(logstd),2)\n","    KLD = -0.5 * torch.sum(1+torch.log(var)-torch.pow(mean,2)-var)\n","    return MSE+KLD\n","\n","def loss_function(recon_x,x,mean,logstd):\n","    # BCE = F.binary_cross_entropy(recon_x,x,reduction='sum')\n","    MSE = MSECriterion(recon_x,x)\n","    return MSE+js_div(recon_x,x)\n","\n","def js_div(p_output, q_output, get_softmax=True):\n","    \"\"\"\n","    Function that measures JS divergence between target and output logits:\n","    \"\"\"\n","    KLDivLoss = nn.KLDivLoss(reduction='batchmean')\n","    if get_softmax:\n","        p_output = F.softmax(p_output)\n","        q_output = F.softmax(q_output)\n","    log_mean_output = ((p_output + q_output )/2).log()\n","    return (KLDivLoss(log_mean_output, p_output) + KLDivLoss(log_mean_output, q_output))/2"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"R352_2Sf7as0","colab":{"base_uri":"https://localhost:8080/","height":535},"executionInfo":{"status":"error","timestamp":1606874696098,"user_tz":-480,"elapsed":3008471,"user":{"displayName":"韩轶凡","photoUrl":"","userId":"03071036090357054572"}},"outputId":"f9c37812-4e3f-440d-a93a-dde934f8712b"},"source":["if __name__ == '__main__':\n","    batchSize = 128\n","    nz=100\n","    nepoch=200\n","    lambda_ = 10\n","    \n","    if not os.path.exists('./img_CVAE-WGANGP'):\n","        os.mkdir('./img_CVAE-WGANGP')\n","\n","    random.seed(1)\n","    torch.manual_seed(1)\n","\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","    cudnn.benchmark = True\n","\n","    dataset = dset.CIFAR10(root='./data',\n","                train=True,\n","                transform=transforms.Compose([transforms.ToTensor()]),\n","                download=True\n","                )\n","\n","    dataloader = torch.utils.data.DataLoader(dataset,\n","                          batch_size=batchSize,\n","                          shuffle=True)\n","\n","    print(\"=====> Initialization\")\n","    vae = VAE().to(device)\n","    # vae.load_state_dict(torch.load('./VAE-WGANGP-VAE_v2.pth'))\n","\n","    # discriminator\n","    D = Discriminator().to(device)\n","    # D.load_state_dict(torch.load('./VAE-GAN-Discriminator.pth'))\n","\n","    # Classifier\n","    C = Classifier().to(device)\n","    # C.load_state_dict(torch.load('./CVAE-GAN-Classifier.pth'))\n","    \n","    criterion = nn.BCELoss().to(device)\n","    MSECriterion = nn.MSELoss().to(device)\n","\n","    optimizerD = optim.Adam(D.parameters(), lr=0.0002,betas=(0.5, 0.999))\n","    optimizerC = optim.Adam(C.parameters(), lr=0.0002,betas=(0.5, 0.999))\n","    optimizerVAE = optim.Adam(vae.parameters(), lr=0.0002,betas=(0.5, 0.999))\n","\n","    # sample_label\n","    specific_label = torch.zeros((100, 10)).to(device)\n","    for i in range(10):\n","      for j in range(10):\n","        specific_label[10*i+j,i] = 1\n","\n","    print(\"=====> Begin training\")\n","    \n","    start_time = time.time()\n","    for epoch in range(nepoch):\n","\n","        # if(epoch%5==0): lambda_ -= 1\n","        \n","        epoch_start_time = time.time()\n","\n","        for i, (data,label) in enumerate(dataloader, 0):\n","            \n","            for n in range(3):\n","              \n","                # data processing\n","                data = data.to(device)\n","                label = label.to(device)\n","                label_onehot = torch.zeros((data.shape[0], 10)).to(device)\n","                label_onehot[torch.arange(data.shape[0]), label] = 1\n","                batch_size = data.shape[0]\n","\n","                # training C with real\n","                C.zero_grad()\n","                output = C(data)\n","                real_label = label_onehot.to(device)\n","                errC = criterion(output, real_label)\n","                errC.backward()\n","                optimizerC.step()\n","                \n","                ###################################################################\n","                # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n","                ###################################################################\n","                for p in D.parameters():\n","                  p.requires_grad = True\n","\n","                # train with real\n","                D.zero_grad()\n","                batch_size = data.shape[0]\n","                real_out = D(data)\n","\n","                # real_label = torch.ones(batch_size).to(device)  \n","                # fake_label = torch.zeros(batch_size).to(device)  \n","\n","                real_label = torch.tensor( [ random.uniform(0.9,1) for _ in range(batch_size) ] ).to(device)\n","                fake_label = torch.tensor( [ random.uniform(0,0.1) for _ in range(batch_size) ] ).to(device)\n","\n","                real_data_score = real_out.mean().item()\n","\n","                # train with fake, taking the noise vector z as the input of D network\n","                z = torch.randn(batch_size, nz+10).to(device)\n","                fake_data = vae.decoder(z)\n","                fake_out = D(fake_data)\n","\n","                # fake_data_score用来输出查看的，是虚假照片的评分，0最假，1为真\n","                fake_data_score = fake_out.mean().item()\n","\n","                alpha = torch.rand((batch_size, 1, 1, 1)).to(device)\n","                x_hat = alpha * data + (1 - alpha) * fake_data\n","\n","                pred_hat = D(x_hat)\n","\n","                gradients = \\\n","                    torch.autograd.grad(outputs=pred_hat, inputs=x_hat, grad_outputs=torch.ones(pred_hat.size()).to(device),\n","                                        create_graph=True, retain_graph=True, only_inputs=True)[0]\n","                gradient_penalty = lambda_ * ((gradients.view(gradients.size()[0], -1).norm(2, 1) - 1) ** 2).mean()\n","\n","                d_loss = torch.mean(fake_out) - torch.mean(real_out) + gradient_penalty\n","                d_loss.backward()\n","                optimizerD.step()\n","\n","            ###################################################\n","            # (2) Update G network which is the decoder of VAE\n","            ###################################################\n","            for p in D.parameters():\n","              p.requires_grad = False\n","            z,mean,logstd = vae.encoder(data)\n","            z = torch.cat([z,label_onehot],1)\n","            vae.zero_grad()\n","            recon_data = vae.decoder(z)\n","            vae_loss = loss_function(recon_data,data,mean,logstd)\n","            vae_loss.backward(retain_graph=True)\n","            optimizerVAE.step()\n","            \n","            ###############################################\n","            # (3) Update G network: maximize log(D(G(z)))\n","            ###############################################\n","            z,mean,logstd = vae.encoder(data)\n","            z = torch.cat([z,label_onehot],1)\n","            vae.zero_grad()\n","            recon_data = vae.decoder(z) \n","            output = D(recon_data)\n","            errVAE = torch.mean(-output)\n","            errVAE.backward()\n","            optimizerVAE.step()\n","\n","            ###############################################\n","            # (4) Update C network\n","            ###############################################   \n","            z,mean,logstd = vae.encoder(data)\n","            z = torch.cat([z,label_onehot],1)\n","            vae.zero_grad()\n","            recon_data = vae.decoder(z)         \n","            output = C(recon_data)\n","            real_label = label_onehot\n","            vae_loss3 = criterion(output, real_label)\n","            vae_loss3.backward()\n","            optimizerVAE.step()\n","\n","        epoch_end_time = time.time()\n","        per_epoch_ptime = epoch_end_time - epoch_start_time\n","        print('[%d/%d] time: %.2f real_score: %.4f fake_score: %.4f '\n","              % (epoch+1, nepoch, per_epoch_ptime,real_data_score,fake_data_score,))\n","    \n","        sample = torch.randn(100, nz).to(device)\n","        sample = torch.cat([sample,specific_label],1)\n","        output = vae.decoder(sample)\n","        fake_images = make_grid(output.cpu(), nrow=10, normalize=True).detach()\n","        save_image(fake_images, './img_CVAE-WGANGP/fake_images-{}.png'.format(epoch + 1))\n","\n","        if(epoch%10==0 and epoch!=0):\n","          !cp -r /content/img_CVAE-WGANGP/ /content/drive/MyDrive\n","\n","    end_time = time.time()\n","    total_time = end_time - start_time\n","    print(\"total time: %.2f \" % total_time )\n","\n","images = []\n","for e in range(nepoch):\n","    img_name = './img_CVAE-WGANGP/fake_images-' + str(e+1) + '.png'\n","    images.append(imageio.imread(img_name))\n","imageio.mimsave('./generation_animation.gif', images, fps=2)\n","\n","# torch.save(vae.state_dict(), './CVAE-WGANGP-VAE.pth')\n","# torch.save(D.state_dict(),'./CVAE-WGANGP-Discriminator.pth')\n","\n","!cp -r /content/img_CVAE-WGAN-GP/ /content/drive/MyDrive\n","!cp -r /content/generation_animation.gif /content/drive/MyDrive"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","=====> Initialization\n","=====> Begin training\n","[1/200] time: 191.70 real_score: 0.4432 fake_score: 0.5923 \n","[2/200] time: 192.58 real_score: 0.4868 fake_score: 0.4857 \n","[3/200] time: 193.31 real_score: 0.5519 fake_score: 0.4309 \n","[4/200] time: 194.70 real_score: 0.5113 fake_score: 0.3356 \n","[5/200] time: 194.58 real_score: 0.5314 fake_score: 0.3438 \n","[6/200] time: 194.97 real_score: 0.5203 fake_score: 0.2955 \n","[7/200] time: 195.21 real_score: 0.5953 fake_score: 0.3360 \n","[8/200] time: 195.21 real_score: 0.6361 fake_score: 0.3156 \n","[9/200] time: 194.49 real_score: 0.6599 fake_score: 0.3582 \n","[10/200] time: 194.96 real_score: 0.6758 fake_score: 0.3719 \n","[11/200] time: 194.49 real_score: 0.6444 fake_score: 0.3811 \n","[12/200] time: 190.54 real_score: 1.0000 fake_score: 1.0000 \n","[13/200] time: 188.26 real_score: 1.0000 fake_score: 1.0000 \n","[14/200] time: 188.19 real_score: 1.0000 fake_score: 1.0000 \n","[15/200] time: 188.08 real_score: 1.0000 fake_score: 1.0000 \n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-ca7d18c78e00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;31m# train with fake, taking the noise vector z as the input of D network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnz\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                 \u001b[0mfake_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mfake_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"A2FfjvXIELGb"},"source":["!cp -r /content/img_CVAE-WGANGP/ /content/drive/MyDrive\n","!cp -r /content/generation_animation.gif /content/drive/MyDrive"],"execution_count":null,"outputs":[]}]}