{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CVAE-WGAN-GP.ipynb","provenance":[{"file_id":"12AjrOZhgNuzXD-xC_WWiRD5Tl61fwQ2E","timestamp":1605435656379}],"collapsed_sections":[],"mount_file_id":"1Cj2wx0qA5pxt4YB9ZwKvkpLk-dVFBO6A","authorship_tag":"ABX9TyP0IrQNRqdURnICNxkwjH7I"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"03eb958e3aac46adb0b1fc7eae2315d3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_946e5cd19e6549989aa19d3046f30003","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8bf6e00f43b042d0995b878e2058d9c6","IPY_MODEL_58e17da935c44112b42f813a85aa2509"]}},"946e5cd19e6549989aa19d3046f30003":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8bf6e00f43b042d0995b878e2058d9c6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_858f668dc7a142aaa422c6b9d9e62bb6","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3871e98a9b5144c884a3d3fcb63bbdbf"}},"58e17da935c44112b42f813a85aa2509":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_69739c346f83477cb9561a860773acbb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9920512/? [00:20&lt;00:00, 25627131.21it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c2e8efac22f042f08c98d8ca6035f621"}},"858f668dc7a142aaa422c6b9d9e62bb6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3871e98a9b5144c884a3d3fcb63bbdbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"69739c346f83477cb9561a860773acbb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c2e8efac22f042f08c98d8ca6035f621":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ed9918bac6a843bda2b780e81acfe6a8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5ab8d6db1de448aa96f9d58259747150","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9b6b6c22c7e0422e9e6f8dabffb7ad93","IPY_MODEL_b4b1a918460840ed9a95888a2ccb140d"]}},"5ab8d6db1de448aa96f9d58259747150":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9b6b6c22c7e0422e9e6f8dabffb7ad93":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2fb510e09a2c4bfdad9dc0eeab45fc14","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0f7008a043284c0bb026502364c3e04e"}},"b4b1a918460840ed9a95888a2ccb140d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2b3f76a335844c5b8e22609fdf220096","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 32768/? [00:00&lt;00:00, 374445.11it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_62e8359b6a6e4baea600b115d983b3f0"}},"2fb510e09a2c4bfdad9dc0eeab45fc14":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0f7008a043284c0bb026502364c3e04e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2b3f76a335844c5b8e22609fdf220096":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"62e8359b6a6e4baea600b115d983b3f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bcde4cd99484477db403e5a3ae4e0925":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_684b8ba7f221436db5d0a8c96af028b1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a5054f9ed28745b3bd1674bc788ca5b3","IPY_MODEL_c5067e44f86c41f1adda216efc65ba66"]}},"684b8ba7f221436db5d0a8c96af028b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a5054f9ed28745b3bd1674bc788ca5b3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c6e72a33f15844c7b025cd1c00849aca","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2abd4d955e714e5aba47baf739b9c1fc"}},"c5067e44f86c41f1adda216efc65ba66":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c69adb5b8fd54f3bbd9e505cf4b3cfee","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1654784/? [00:19&lt;00:00, 120638.58it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c132cf45cac64a14b223c118424ecefe"}},"c6e72a33f15844c7b025cd1c00849aca":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2abd4d955e714e5aba47baf739b9c1fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c69adb5b8fd54f3bbd9e505cf4b3cfee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c132cf45cac64a14b223c118424ecefe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3d6ccdf000eb4fc6b5223b6062cf4c55":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8a41f1217f7f41a0818d3662c6085194","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a317666948764c35bfed7532cd1b30fc","IPY_MODEL_70c6315153e14a0ab7ebaf845545a5b8"]}},"8a41f1217f7f41a0818d3662c6085194":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a317666948764c35bfed7532cd1b30fc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_12df44ac2d454a66b7234e0ab25ef915","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_59cfbb8ff0374606a19c61f6cfe1bf97"}},"70c6315153e14a0ab7ebaf845545a5b8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d49c7f7c1d72428f9a94ab9418a08bb1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/? [00:00&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_400ffb4ad0894a0fb2f9e38344ac687d"}},"12df44ac2d454a66b7234e0ab25ef915":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"59cfbb8ff0374606a19c61f6cfe1bf97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d49c7f7c1d72428f9a94ab9418a08bb1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"400ffb4ad0894a0fb2f9e38344ac687d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"Wja_6s6s6vbi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606647686615,"user_tz":-480,"elapsed":1773,"user":{"displayName":"韩轶凡","photoUrl":"","userId":"03071036090357054572"}},"outputId":"e71cbaa4-e8ed-444c-bbc5-d7b8ea803190"},"source":["!/opt/bin/nvidia-smi\n","\n","!rm -rf /content/sample_data\n","\n","!rm -rf /content/img_VAE-WGANGP"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Sun Nov 29 11:01:26 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   59C    P8    11W /  70W |      0MiB / 15079MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"82k1f_YN6_lg","executionInfo":{"status":"ok","timestamp":1606647704970,"user_tz":-480,"elapsed":4797,"user":{"displayName":"韩轶凡","photoUrl":"","userId":"03071036090357054572"}}},"source":["from __future__ import print_function\n","import argparse\n","import os,time\n","import random\n","import math\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.backends.cudnn as cudnn\n","import torch.optim as optim\n","import torch.utils.data\n","import torchvision.datasets as dset\n","import torchvision.transforms as transforms\n","from torchvision.utils import save_image\n","from torchvision.utils import make_grid\n","import torch.nn.functional as F\n","\n","import imageio\n","import matplotlib.pyplot as plt"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"h9a1gMGC7Rag","executionInfo":{"status":"ok","timestamp":1606647706214,"user_tz":-480,"elapsed":1242,"user":{"displayName":"韩轶凡","photoUrl":"","userId":"03071036090357054572"}}},"source":["class VAE(nn.Module):\n","    def __init__(self):\n","\n","        super(VAE, self).__init__()\n","        \n","        self.encoder_conv = nn.Sequential(\n","            nn.Conv2d(1,16,kernel_size=3,stride=2,padding=1),\n","            \n","            nn.LeakyReLU(0.2,inplace=True),    # batchnorm 放在 leakyrelu 后效果更好\n","            nn.BatchNorm2d(16),\n","            nn.Conv2d(16,32,kernel_size=3,stride=2,padding=1),\n","            \n","            nn.LeakyReLU(0.2,inplace=True),\n","            nn.BatchNorm2d(32),\n","            nn.Conv2d(32,32,kernel_size=3,stride=1,padding=1),\n","            \n","            nn.LeakyReLU(0.2,inplace=True),\n","            nn.BatchNorm2d(32),\n","        )\n","\n","        self.encoder_fc1=nn.Linear(32*7*7,nz)\n","        self.encoder_fc2=nn.Linear(32*7*7,nz)\n","        self.Sigmoid = nn.Sigmoid()\n","        self.decoder_fc = nn.Linear(nz+10,32 * 7 * 7)\n","        self.decoder_deconv = nn.Sequential(\n","            nn.ConvTranspose2d(32, 16, 4, 2, 1),\n","            nn.LeakyReLU(0.2,inplace=True),\n","            nn.ConvTranspose2d(16, 1, 4, 2, 1),\n","            nn.Sigmoid(),\n","        )\n","\n","    def noise_reparameterize(self,mean,logvar):\n","        eps = torch.randn(mean.shape).to(device)\n","        z = mean + eps * torch.exp(logvar)\n","        return z\n","\n","    def encoder(self,x):\n","        out1, out2 = self.encoder_conv(x), self.encoder_conv(x)\n","        mean = self.encoder_fc1(out1.view(out1.shape[0], -1))\n","        logstd = self.encoder_fc2(out2.view(out2.shape[0], -1))\n","        z = self.noise_reparameterize(mean, logstd)\n","        return z,mean,logstd\n","\n","    def decoder(self,z):\n","        out3 = self.decoder_fc(z)\n","        out3 = out3.view(out3.shape[0], 32, 7, 7)\n","        out3 = self.decoder_deconv(out3)\n","        return out3\n","\n","    def forward(self, x):\n","        z = self.encoder(x)\n","        output = self.decoder(z)\n","        return output"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"SQkWtBQ57UQq"},"source":["class Discriminator(nn.Module):\n","    def __init__(self,outputn=1):\n","        super(Discriminator, self).__init__()\n","        self.dis = nn.Sequential(\n","            nn.Conv2d(1, 32, 3, stride=1, padding=1),\n","            nn.LeakyReLU(0.2, True),\n","            nn.MaxPool2d((2, 2)),\n","\n","            nn.Conv2d(32, 64, 3, stride=1, padding=1),\n","            nn.LeakyReLU(0.2, True),\n","            nn.MaxPool2d((2, 2)),\n","        )\n","        self.fc = nn.Sequential(\n","            nn.Linear(7 * 7 * 64, 1024),\n","            nn.LeakyReLU(0.2, True),\n","            nn.Linear(1024, outputn),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, input):\n","        x = self.dis(input)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","        return x.squeeze(1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ro2BSkC_7WfX"},"source":["def loss_function(recon_x,x,mean,logstd):\n","    # BCE = F.binary_cross_entropy(recon_x,x,reduction='sum')\n","    MSE = MSECriterion(recon_x,x)\n","    # 因为var是标准差的自然对数，先求自然对数然后平方转换成方差\n","    var = torch.pow(torch.exp(logstd),2)\n","    KLD = -0.5 * torch.sum(1+torch.log(var)-torch.pow(mean,2)-var)\n","    return MSE+KLD"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R352_2Sf7as0","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["03eb958e3aac46adb0b1fc7eae2315d3","946e5cd19e6549989aa19d3046f30003","8bf6e00f43b042d0995b878e2058d9c6","58e17da935c44112b42f813a85aa2509","858f668dc7a142aaa422c6b9d9e62bb6","3871e98a9b5144c884a3d3fcb63bbdbf","69739c346f83477cb9561a860773acbb","c2e8efac22f042f08c98d8ca6035f621","ed9918bac6a843bda2b780e81acfe6a8","5ab8d6db1de448aa96f9d58259747150","9b6b6c22c7e0422e9e6f8dabffb7ad93","b4b1a918460840ed9a95888a2ccb140d","2fb510e09a2c4bfdad9dc0eeab45fc14","0f7008a043284c0bb026502364c3e04e","2b3f76a335844c5b8e22609fdf220096","62e8359b6a6e4baea600b115d983b3f0","bcde4cd99484477db403e5a3ae4e0925","684b8ba7f221436db5d0a8c96af028b1","a5054f9ed28745b3bd1674bc788ca5b3","c5067e44f86c41f1adda216efc65ba66","c6e72a33f15844c7b025cd1c00849aca","2abd4d955e714e5aba47baf739b9c1fc","c69adb5b8fd54f3bbd9e505cf4b3cfee","c132cf45cac64a14b223c118424ecefe","3d6ccdf000eb4fc6b5223b6062cf4c55","8a41f1217f7f41a0818d3662c6085194","a317666948764c35bfed7532cd1b30fc","70c6315153e14a0ab7ebaf845545a5b8","12df44ac2d454a66b7234e0ab25ef915","59cfbb8ff0374606a19c61f6cfe1bf97","d49c7f7c1d72428f9a94ab9418a08bb1","400ffb4ad0894a0fb2f9e38344ac687d"]},"executionInfo":{"status":"error","timestamp":1606274732478,"user_tz":-480,"elapsed":3235829,"user":{"displayName":"韩轶凡","photoUrl":"","userId":"03071036090357054572"}},"outputId":"02c6e2e5-3426-4d47-d198-75f369f05daa"},"source":["if __name__ == '__main__':\n","    batchSize = 128\n","    imageSize = 28\n","    nz=100\n","    nepoch=200\n","    lambda_ = 10\n","    \n","    if not os.path.exists('./img_CVAE-WGANGP'):\n","        os.mkdir('./img_CVAE-WGANGP')\n","\n","    # random.seed(88)\n","    # torch.manual_seed(88)\n","\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","    cudnn.benchmark = True\n","\n","    dataset = dset.MNIST(root='./data',\n","                train=True,\n","                transform=transforms.Compose([transforms.ToTensor()]),\n","                download=True\n","                )\n","\n","    dataloader = torch.utils.data.DataLoader(dataset,\n","                          batch_size=batchSize,\n","                          shuffle=True)\n","\n","    print(\"=====> Initialization\")\n","    vae = VAE().to(device)\n","    # vae.load_state_dict(torch.load('./VAE-WGANGP-VAE_v2.pth'))\n","\n","    # discriminator\n","    D = Discriminator(1).to(device)\n","    # D.load_state_dict(torch.load('./VAE-GAN-Discriminator.pth'))\n","\n","    # Classifier\n","    C = Discriminator(10).to(device)\n","    # C.load_state_dict(torch.load('./CVAE-GAN-Classifier.pth'))\n","    \n","    criterion = nn.BCELoss().to(device)\n","    MSECriterion = nn.MSELoss().to(device)\n","\n","    optimizerD = optim.Adam(D.parameters(), lr=0.0002,betas=(0.5, 0.999))\n","    optimizerC = optim.Adam(C.parameters(), lr=0.0002,betas=(0.5, 0.999))\n","    optimizerVAE = optim.Adam(vae.parameters(), lr=0.0002,betas=(0.5, 0.999))\n","\n","    # sample_label\n","    s_label = []\n","    for i in [1,8,0,9,4,0,1,0,5,3]:\n","      s_label += [ i for _ in range(8)]\n","    specific_label = torch.zeros((80, 10)).cuda()\n","    specific_label[torch.arange(80), s_label] = 1\n","\n","    print(\"=====> Begin training\")\n","    \n","    start_time = time.time()\n","    for epoch in range(nepoch):\n","\n","        if(epoch%5==0): lambda_ -= 1\n","        \n","        epoch_start_time = time.time()\n","\n","        for i, (data,label) in enumerate(dataloader, 0):\n","            \n","            for n in range(1):\n","              \n","                # data processing\n","                data = data.to(device)\n","                label = label.to(device)\n","                label_onehot = torch.zeros((data.shape[0], 10)).to(device)\n","                label_onehot[torch.arange(data.shape[0]), label] = 1\n","                batch_size = data.shape[0]\n","\n","                # training C with real\n","                output = C(data)\n","                real_label = label_onehot.to(device)\n","                errC = criterion(output, real_label)\n","                C.zero_grad()\n","                errC.backward()\n","                optimizerC.step()\n","                \n","                ###################################################################\n","                # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n","                ###################################################################\n","\n","                # train with real\n","                D.zero_grad()\n","                batch_size = data.shape[0]\n","                real_out = D(data)\n","\n","                real_label = torch.ones(batch_size).to(device)  \n","                fake_label = torch.zeros(batch_size).to(device)  \n","\n","                real_data_score = real_out.mean().item()\n","\n","                # train with fake, taking the noise vector z as the input of D network\n","                z = torch.randn(batch_size, nz+10).to(device)\n","                fake_data = vae.decoder(z)\n","                fake_out = D(fake_data)\n","\n","                # fake_data_score用来输出查看的，是虚假照片的评分，0最假，1为真\n","                fake_data_score = fake_out.mean().item()\n","\n","                alpha = torch.rand((batch_size, 1, 1, 1)).to(device)\n","                x_hat = alpha * data + (1 - alpha) * fake_data\n","\n","                pred_hat = D(x_hat)\n","\n","                gradients = \\\n","                    torch.autograd.grad(outputs=pred_hat, inputs=x_hat, grad_outputs=torch.ones(pred_hat.size()).to(device),\n","                                        create_graph=True, retain_graph=True, only_inputs=True)[0]\n","                gradient_penalty = lambda_ * ((gradients.view(gradients.size()[0], -1).norm(2, 1) - 1) ** 2).mean()\n","\n","                d_loss = torch.mean(fake_out) - torch.mean(real_out) + gradient_penalty\n","                d_loss.backward()\n","                optimizerD.step()\n","\n","            ###################################################\n","            # (2) Update G network which is the decoder of VAE\n","            ###################################################\n","            z,mean,logstd = vae.encoder(data)\n","            z = torch.cat([z,label_onehot],1)\n","            recon_data = vae.decoder(z)\n","            vae.zero_grad()\n","            vae_loss = loss_function(recon_data,data,mean,logstd)\n","            vae_loss.backward(retain_graph=True)\n","            optimizerVAE.step()\n","            \n","            ###############################################\n","            # (3) Update G network: maximize log(D(G(z)))\n","            ###############################################\n","            z,mean,logstd = vae.encoder(data)\n","            z = torch.cat([z,label_onehot],1)\n","            recon_data = vae.decoder(z)\n","            vae.zero_grad()\n","            real_label = torch.ones(batch_size).to(device)  \n","            output = D(recon_data)\n","            errVAE = torch.mean(-output)\n","            errVAE.backward()\n","            D_G_z2 = output.mean().item()\n","            optimizerVAE.step()\n","\n","            ###############################################\n","            # (4) Update C network\n","            ###############################################   \n","            z,mean,logstd = vae.encoder(data)\n","            z = torch.cat([z,label_onehot],1)\n","            recon_data = vae.decoder(z)         \n","            output = C(recon_data)\n","            real_label = label_onehot\n","            vae_loss3 = criterion(output, real_label)\n","            vae.zero_grad()\n","            vae_loss3.backward()\n","            optimizerVAE.step()\n","\n","        epoch_end_time = time.time()\n","        per_epoch_ptime = epoch_end_time - epoch_start_time\n","        print('[%d/%d] time: %.2f real_score: %.4f fake_score: %.4f '\n","              % (epoch+1, nepoch, per_epoch_ptime,real_data_score,fake_data_score,))\n","    \n","        sample = torch.randn(80, nz).to(device)\n","        sample = torch.cat([sample,specific_label],1)\n","        output = vae.decoder(sample)\n","        fake_images = make_grid(output.cpu(), nrow=8, normalize=True).detach()\n","        save_image(fake_images, './img_CVAE-WGANGP/fake_images-{}.png'.format(epoch + 1))\n","\n","    end_time = time.time()\n","    total_time = end_time - start_time\n","    print(\"total time: %.2f \" % total_time )\n","\n","images = []\n","for e in range(nepoch):\n","    img_name = './img_CVAE-WGANGP/fake_images-' + str(e+1) + '.png'\n","    images.append(imageio.imread(img_name))\n","imageio.mimsave('./generation_animation.gif', images, fps=2)\n","\n","# torch.save(vae.state_dict(), './CVAE-WGANGP-VAE.pth')\n","# torch.save(D.state_dict(),'./CVAE-WGANGP-Discriminator.pth')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"03eb958e3aac46adb0b1fc7eae2315d3","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ed9918bac6a843bda2b780e81acfe6a8","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bcde4cd99484477db403e5a3ae4e0925","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3d6ccdf000eb4fc6b5223b6062cf4c55","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","Processing...\n","Done!\n","=====> Initialization\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n","  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"],"name":"stderr"},{"output_type":"stream","text":["=====> Begin training\n","[1/200] time: 26.29 real_score: 0.8284 fake_score: 0.4258 \n","[2/200] time: 26.07 real_score: 0.8145 fake_score: 0.4912 \n","[3/200] time: 26.90 real_score: 0.7789 fake_score: 0.4394 \n","[4/200] time: 26.03 real_score: 0.7556 fake_score: 0.4260 \n","[5/200] time: 26.35 real_score: 0.7427 fake_score: 0.2168 \n","[6/200] time: 26.25 real_score: 0.8100 fake_score: 0.1560 \n","[7/200] time: 26.24 real_score: 0.8699 fake_score: 0.1333 \n","[8/200] time: 26.46 real_score: 0.8342 fake_score: 0.0896 \n","[9/200] time: 26.54 real_score: 0.8932 fake_score: 0.1374 \n","[10/200] time: 25.99 real_score: 0.9192 fake_score: 0.1053 \n","[11/200] time: 25.84 real_score: 0.9423 fake_score: 0.1213 \n","[12/200] time: 26.51 real_score: 0.9175 fake_score: 0.0779 \n","[13/200] time: 26.20 real_score: 0.9342 fake_score: 0.1326 \n","[14/200] time: 25.77 real_score: 0.8873 fake_score: 0.0785 \n","[15/200] time: 26.57 real_score: 0.9450 fake_score: 0.1039 \n","[16/200] time: 26.35 real_score: 0.9483 fake_score: 0.0750 \n","[17/200] time: 26.03 real_score: 0.9424 fake_score: 0.0947 \n","[18/200] time: 26.43 real_score: 0.9290 fake_score: 0.1001 \n","[19/200] time: 25.74 real_score: 0.9107 fake_score: 0.1055 \n","[20/200] time: 26.06 real_score: 0.9310 fake_score: 0.0957 \n","[21/200] time: 25.91 real_score: 0.9407 fake_score: 0.0605 \n","[22/200] time: 26.06 real_score: 0.8973 fake_score: 0.0511 \n","[23/200] time: 26.06 real_score: 0.9698 fake_score: 0.0798 \n","[24/200] time: 26.33 real_score: 0.9498 fake_score: 0.0962 \n","[25/200] time: 26.33 real_score: 0.9549 fake_score: 0.0643 \n","[26/200] time: 25.77 real_score: 0.9436 fake_score: 0.0585 \n","[27/200] time: 26.42 real_score: 0.9239 fake_score: 0.0550 \n","[28/200] time: 26.49 real_score: 0.9569 fake_score: 0.0541 \n","[29/200] time: 26.48 real_score: 0.9395 fake_score: 0.0523 \n","[30/200] time: 26.36 real_score: 0.9470 fake_score: 0.0368 \n","[31/200] time: 25.92 real_score: 0.9634 fake_score: 0.0390 \n","[32/200] time: 26.05 real_score: 0.9629 fake_score: 0.0392 \n","[33/200] time: 26.01 real_score: 0.9707 fake_score: 0.0439 \n","[34/200] time: 25.97 real_score: 0.9646 fake_score: 0.0269 \n","[35/200] time: 25.82 real_score: 0.9698 fake_score: 0.0504 \n","[36/200] time: 26.02 real_score: 0.9648 fake_score: 0.0248 \n","[37/200] time: 26.07 real_score: 0.9588 fake_score: 0.0459 \n","[38/200] time: 26.54 real_score: 0.9436 fake_score: 0.0363 \n","[39/200] time: 25.97 real_score: 0.9742 fake_score: 0.0218 \n","[40/200] time: 26.20 real_score: 0.9685 fake_score: 0.0193 \n","[41/200] time: 26.24 real_score: 0.9772 fake_score: 0.0243 \n","[42/200] time: 26.22 real_score: 0.9758 fake_score: 0.0186 \n","[43/200] time: 26.37 real_score: 0.9845 fake_score: 0.0225 \n","[44/200] time: 26.08 real_score: 0.9831 fake_score: 0.0174 \n","[45/200] time: 26.11 real_score: 0.9858 fake_score: 0.0182 \n","[46/200] time: 26.24 real_score: 0.9994 fake_score: 0.0014 \n","[47/200] time: 26.08 real_score: 0.9987 fake_score: 0.0021 \n","[48/200] time: 26.51 real_score: 0.9996 fake_score: 0.0029 \n","[49/200] time: 26.38 real_score: 0.9777 fake_score: 0.0000 \n","[50/200] time: 26.18 real_score: 1.0000 fake_score: 0.0071 \n","[51/200] time: 26.34 real_score: 0.0000 fake_score: 0.0000 \n","[52/200] time: 26.45 real_score: 0.0000 fake_score: 0.0000 \n","[53/200] time: 25.91 real_score: 0.0000 fake_score: 0.0000 \n","[54/200] time: 25.96 real_score: 0.0000 fake_score: 0.0000 \n","[55/200] time: 25.97 real_score: 0.0000 fake_score: 0.0000 \n","[56/200] time: 26.21 real_score: 0.0000 fake_score: 0.0000 \n","[57/200] time: 25.82 real_score: 0.0000 fake_score: 0.0000 \n","[58/200] time: 26.05 real_score: 0.0000 fake_score: 0.0000 \n","[59/200] time: 25.73 real_score: 0.0000 fake_score: 0.0000 \n","[60/200] time: 25.92 real_score: 0.0000 fake_score: 0.0000 \n","[61/200] time: 25.61 real_score: 0.0000 fake_score: 0.0000 \n","[62/200] time: 26.29 real_score: 0.0000 fake_score: 0.0000 \n","[63/200] time: 26.35 real_score: 0.0000 fake_score: 0.0000 \n","[64/200] time: 26.44 real_score: 0.0000 fake_score: 0.0000 \n","[65/200] time: 26.79 real_score: 0.0000 fake_score: 0.0000 \n","[66/200] time: 26.18 real_score: 0.0000 fake_score: 0.0000 \n","[67/200] time: 26.03 real_score: 0.0000 fake_score: 0.0000 \n","[68/200] time: 26.42 real_score: 0.0000 fake_score: 0.0000 \n","[69/200] time: 26.23 real_score: 0.0000 fake_score: 0.0000 \n","[70/200] time: 25.84 real_score: 0.0000 fake_score: 0.0000 \n","[71/200] time: 26.24 real_score: 0.0000 fake_score: 0.0000 \n","[72/200] time: 26.05 real_score: 0.0000 fake_score: 0.0000 \n","[73/200] time: 25.72 real_score: 0.0000 fake_score: 0.0000 \n","[74/200] time: 26.36 real_score: 0.0000 fake_score: 0.0000 \n","[75/200] time: 26.39 real_score: 0.0000 fake_score: 0.0000 \n","[76/200] time: 26.23 real_score: 0.0000 fake_score: 0.0000 \n","[77/200] time: 26.49 real_score: 0.0000 fake_score: 0.0000 \n","[78/200] time: 26.07 real_score: 0.0000 fake_score: 0.0000 \n","[79/200] time: 26.18 real_score: 0.0000 fake_score: 0.0000 \n","[80/200] time: 26.15 real_score: 0.0000 fake_score: 0.0000 \n","[81/200] time: 25.73 real_score: 0.0000 fake_score: 0.0000 \n","[82/200] time: 25.83 real_score: 0.0000 fake_score: 0.0000 \n","[83/200] time: 26.07 real_score: 0.0000 fake_score: 0.0000 \n","[84/200] time: 26.23 real_score: 0.0000 fake_score: 0.0000 \n","[85/200] time: 26.32 real_score: 0.0000 fake_score: 0.0000 \n","[86/200] time: 25.96 real_score: 0.0000 fake_score: 0.0000 \n","[87/200] time: 26.25 real_score: 0.0000 fake_score: 0.0000 \n","[88/200] time: 26.12 real_score: 0.0000 fake_score: 0.0000 \n","[89/200] time: 25.95 real_score: 0.0000 fake_score: 0.0000 \n","[90/200] time: 26.16 real_score: 0.0000 fake_score: 0.0000 \n","[91/200] time: 26.25 real_score: 0.0000 fake_score: 0.0000 \n","[92/200] time: 26.38 real_score: 0.0000 fake_score: 0.0000 \n","[93/200] time: 26.12 real_score: 0.0000 fake_score: 0.0000 \n","[94/200] time: 26.64 real_score: 0.0000 fake_score: 0.0000 \n","[95/200] time: 26.19 real_score: 0.0000 fake_score: 0.0000 \n","[96/200] time: 26.20 real_score: 0.0000 fake_score: 0.0000 \n","[97/200] time: 26.25 real_score: 0.0000 fake_score: 0.0000 \n","[98/200] time: 25.73 real_score: 0.0000 fake_score: 0.0000 \n","[99/200] time: 25.83 real_score: 0.0000 fake_score: 0.0000 \n","[100/200] time: 26.48 real_score: 0.0000 fake_score: 0.0000 \n","[101/200] time: 25.90 real_score: 0.0000 fake_score: 0.0000 \n","[102/200] time: 25.81 real_score: 0.0000 fake_score: 0.0000 \n","[103/200] time: 26.35 real_score: 0.0000 fake_score: 0.0000 \n","[104/200] time: 26.13 real_score: 0.0000 fake_score: 0.0000 \n","[105/200] time: 26.05 real_score: 0.0000 fake_score: 0.0000 \n","[106/200] time: 25.89 real_score: 0.0000 fake_score: 0.0000 \n","[107/200] time: 26.13 real_score: 0.0000 fake_score: 0.0000 \n","[108/200] time: 26.43 real_score: 0.0000 fake_score: 0.0000 \n","[109/200] time: 25.76 real_score: 0.0000 fake_score: 0.0000 \n","[110/200] time: 26.32 real_score: 0.0000 fake_score: 0.0000 \n","[111/200] time: 26.05 real_score: 0.0000 fake_score: 0.0000 \n","[112/200] time: 25.91 real_score: 0.0000 fake_score: 0.0000 \n","[113/200] time: 25.72 real_score: 0.0000 fake_score: 0.0000 \n","[114/200] time: 26.52 real_score: 0.0000 fake_score: 0.0000 \n","[115/200] time: 26.43 real_score: 0.0000 fake_score: 0.0000 \n","[116/200] time: 26.17 real_score: 0.0000 fake_score: 0.0000 \n","[117/200] time: 26.12 real_score: 0.0000 fake_score: 0.0000 \n","[118/200] time: 26.05 real_score: 0.0000 fake_score: 0.0000 \n","[119/200] time: 26.51 real_score: 0.0000 fake_score: 0.0000 \n","[120/200] time: 26.00 real_score: 0.0000 fake_score: 0.0000 \n","[121/200] time: 26.37 real_score: 0.0000 fake_score: 0.0000 \n","[122/200] time: 25.97 real_score: 0.0000 fake_score: 0.0000 \n","[123/200] time: 25.98 real_score: 0.0000 fake_score: 0.0000 \n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-731d3634dcef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 gradients =                     torch.autograd.grad(outputs=pred_hat, inputs=x_hat, grad_outputs=torch.ones(pred_hat.size()).to(device),\n\u001b[0;32m--> 110\u001b[0;31m                                         create_graph=True, retain_graph=True, only_inputs=True)[0]\n\u001b[0m\u001b[1;32m    111\u001b[0m                 \u001b[0mgradient_penalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlambda_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0moverridable_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverridable_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         return handle_torch_function(\n\u001b[1;32m    180\u001b[0m             \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/overrides.py\u001b[0m in \u001b[0;36mhas_torch_function\u001b[0;34m(relevant_args)\u001b[0m\n\u001b[1;32m   1084\u001b[0m     \u001b[0mimplementations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m     \"\"\"\n\u001b[0;32m-> 1086\u001b[0;31m     return _is_torch_function_enabled() and any(\n\u001b[0m\u001b[1;32m   1087\u001b[0m         \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m         \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__torch_function__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_disabled_torch_function_impl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}