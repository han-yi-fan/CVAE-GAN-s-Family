{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"new_CVAE-WGAN.ipynb","provenance":[{"file_id":"12AjrOZhgNuzXD-xC_WWiRD5Tl61fwQ2E","timestamp":1605435656379}],"collapsed_sections":[],"mount_file_id":"10SVjeGuLIvbPTyrFTWfDI9-tSRCA0GJi","authorship_tag":"ABX9TyMgtbs2+F/y2IvEHl3WEoRz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Wja_6s6s6vbi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606558578213,"user_tz":-480,"elapsed":1781,"user":{"displayName":"韩轶凡","photoUrl":"","userId":"03071036090357054572"}},"outputId":"35258b92-2231-4082-f4cc-1896c9619620"},"source":["!/opt/bin/nvidia-smi\n","\n","!rm -rf /content/sample_data\n","\n","!rm -rf /content/img_CVAE-WGAN"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Sat Nov 28 10:16:17 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   68C    P0    30W /  70W |   2991MiB / 15079MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"82k1f_YN6_lg","executionInfo":{"status":"ok","timestamp":1606552925278,"user_tz":-480,"elapsed":1154,"user":{"displayName":"韩轶凡","photoUrl":"","userId":"03071036090357054572"}}},"source":["from __future__ import print_function\n","import argparse\n","import os,time\n","import random\n","import math\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.backends.cudnn as cudnn\n","import torch.optim as optim\n","import torch.utils.data\n","import torchvision.datasets as dset\n","import torchvision.transforms as transforms\n","from torchvision.utils import save_image\n","from torchvision.utils import make_grid\n","import torch.nn.functional as F\n","\n","import imageio\n","import matplotlib.pyplot as plt"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"h9a1gMGC7Rag","executionInfo":{"status":"ok","timestamp":1606552926503,"user_tz":-480,"elapsed":1120,"user":{"displayName":"韩轶凡","photoUrl":"","userId":"03071036090357054572"}}},"source":["class VAE(nn.Module):\n","    def __init__(self):\n","\n","        super(VAE, self).__init__()\n","        \n","        self.encoder_conv = nn.Sequential(\n","            nn.Conv2d(3,16,kernel_size=3,stride=2,padding=1),\n","            nn.BatchNorm2d(16),\n","            nn.LeakyReLU(0.2,inplace=True),\n","            nn.Conv2d(16,64,kernel_size=3,stride=2,padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.LeakyReLU(0.2,inplace=True),\n","            nn.Conv2d(64,32,kernel_size=3,stride=1,padding=1),\n","            nn.BatchNorm2d(32),\n","            nn.LeakyReLU(0.2,inplace=True),\n","        )\n","\n","        self.encoder_fc1=nn.Linear(32*8*8,nz)\n","        self.encoder_fc2=nn.Linear(32*8*8,nz)\n","        self.Sigmoid = nn.Sigmoid()\n","       \n","        self.decoder_fc=nn.Linear(nz+10,3 * 64 * 64)\n","        self.br=nn.Sequential(\n","            nn.BatchNorm2d(3),\n","            nn.ReLU(True),\n","        )\n","        self.gen = nn.Sequential(\n","            nn.Conv2d(3,64,3,stride=1,padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(True),\n","\n","            nn.Conv2d(64,32,3,stride=1,padding=1),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(True),\n","\n","            nn.Conv2d(32,3,3,stride=2,padding=1),\n","            nn.Tanh(),\n","        )\n","    \n","    def decoder(self,z):\n","        x = self.decoder_fc(z)\n","        x=x.view(x.shape[0],3,64,64)\n","        x=self.br(x)\n","        x=self.gen(x)\n","        return x\n","\n","    def noise_reparameterize(self,mean,logvar):\n","        eps = torch.randn(mean.shape).to(device)\n","        z = mean + eps * torch.exp(logvar)\n","        return z\n","\n","    def encoder(self,x):\n","        out1, out2 = self.encoder_conv(x), self.encoder_conv(x)\n","        mean = self.encoder_fc1(out1.view(out1.shape[0], -1))\n","        logstd = self.encoder_fc2(out2.view(out2.shape[0], -1))\n","        z = self.noise_reparameterize(mean, logstd)\n","        return z,mean,logstd\n","\n","    def forward(self, x):\n","        z = self.encoder(x)\n","        output = self.decoder(z)\n","        return output"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"SQkWtBQ57UQq","executionInfo":{"status":"ok","timestamp":1606552520467,"user_tz":-480,"elapsed":1166,"user":{"displayName":"韩轶凡","photoUrl":"","userId":"03071036090357054572"}}},"source":["class Classifier(nn.Module):\n","    def __init__(self):\n","        super(Classifier, self).__init__()\n","        self.dis = nn.Sequential(\n","            nn.Conv2d(3, 32, 3, stride=1, padding=1),\n","            nn.LeakyReLU(0.2, True),\n","            nn.MaxPool2d((2, 2)),\n","\n","            nn.Conv2d(32, 64, 3, stride=1, padding=1),\n","            nn.LeakyReLU(0.2, True),\n","            nn.MaxPool2d((2, 2)),\n","        )\n","        self.fc = nn.Sequential(\n","            nn.Linear(8 * 8 * 64, 1024),\n","            nn.LeakyReLU(0.2, True),\n","            nn.Linear(1024, 10),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, input):\n","        x = self.dis(input)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","        return x.squeeze(1)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"rJB3buUyCvIq","executionInfo":{"status":"ok","timestamp":1606551962554,"user_tz":-480,"elapsed":793,"user":{"displayName":"韩轶凡","photoUrl":"","userId":"03071036090357054572"}}},"source":["class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","        self.dis = nn.Sequential(\n","            nn.Conv2d(3,32,3,stride=1,padding=1),\n","            nn.LeakyReLU(0.2,True),\n","            nn.MaxPool2d((2,2)),\n","\n","            nn.Conv2d(32,64,3,stride=1,padding=1),\n","            nn.LeakyReLU(0.2,True),\n","            nn.MaxPool2d((2,2)),\n","        )\n","        self.fc = nn.Sequential(\n","            nn.Linear(8*8*64,1024),\n","            nn.LeakyReLU(0.2,True),\n","            nn.Linear(1024,1),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        x = self.dis(x)\n","        x=x.view(x.size(0),-1)\n","        x=self.fc(x)\n","        x = x.view(x.size(0))\n","        return x"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ro2BSkC_7WfX","executionInfo":{"status":"ok","timestamp":1606551964675,"user_tz":-480,"elapsed":1544,"user":{"displayName":"韩轶凡","photoUrl":"","userId":"03071036090357054572"}}},"source":["def loss_function(recon_x,x,mean,logstd):\n","    # BCE = F.binary_cross_entropy(recon_x,x,reduction='sum')\n","    MSE = MSECriterion(recon_x,x)\n","    # 因为var是标准差的自然对数，先求自然对数然后平方转换成方差\n","    var = torch.pow(torch.exp(logstd),2)\n","    KLD = -0.5 * torch.sum(1+torch.log(var)-torch.pow(mean,2)-var)\n","    return MSE+KLD"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"R352_2Sf7as0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606574634257,"user_tz":-480,"elapsed":12843263,"user":{"displayName":"韩轶凡","photoUrl":"","userId":"03071036090357054572"}},"outputId":"2395be6e-fce5-45c1-c595-a5f02310aa5a"},"source":["if __name__ == '__main__':\n","    batchSize = 128\n","    imageSize = 28\n","    nz=100\n","    nepoch= 200\n","    lambda_ = 10\n","    c = 0.005\n","\n","    if not os.path.exists('./img_CVAE-WGAN'):\n","        os.mkdir('./img_CVAE-WGAN')\n","\n","    random.seed(1)\n","    torch.manual_seed(1)\n","\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","    cudnn.benchmark = True\n","\n","    dataset = dset.CIFAR10(root='./data',\n","                train=True,\n","                transform=transforms.Compose([transforms.ToTensor()]),\n","                download=True\n","                )\n","\n","    dataloader = torch.utils.data.DataLoader(dataset,\n","                          batch_size=batchSize,\n","                          shuffle=True)\n","\n","    print(\"=====> Initialization\")\n","    vae = VAE().to(device)\n","    # vae.load_state_dict(torch.load('./VAE-WGANGP-VAE_v2.pth'))\n","\n","    # discriminator\n","    D = Discriminator().to(device)\n","    # D.load_state_dict(torch.load('./VAE-GAN-Discriminator.pth'))\n","\n","    # Classifier\n","    C = Classifier().to(device)\n","    # C.load_state_dict(torch.load('./CVAE-GAN-Classifier.pth'))\n","    \n","    criterion = nn.BCELoss().to(device)\n","    MSECriterion = nn.MSELoss().to(device)\n","\n","    # best=0.0001,0.0004,0.0008\n","    optimizerD = optim.Adam(D.parameters(), lr=0.0002,betas=(0.5, 0.999))\n","    optimizerC = optim.Adam(C.parameters(), lr=0.0002,betas=(0.5, 0.999))\n","    optimizerVAE = optim.Adam(vae.parameters(), lr=0.0002,betas=(0.5, 0.999))\n","\n","    # sample_label\n","    specific_label = torch.zeros((100, 10)).cuda()\n","    for i in range(10):\n","      for j in range(10):\n","        specific_label[10*i+j,i] = 1\n","\n","    print(\"=====> Begin training\")\n","    \n","    start_time = time.time()\n","    for epoch in range(nepoch):\n","\n","        if(epoch%5==0): lambda_ -= 1\n","        \n","        epoch_start_time = time.time()\n","\n","        for i, (data,label) in enumerate(dataloader, 0):\n","\n","            # data processing\n","            data = data.to(device)\n","            label = label.to(device)\n","            label_onehot = torch.zeros((data.shape[0], 10)).to(device)\n","            label_onehot[torch.arange(data.shape[0]), label] = 1\n","            batch_size = data.shape[0]\n","\n","\n","            for n in range(1):\n","            # if epoch % 2 == 0:\n","              \n","\n","                # training C with real\n","                C.zero_grad()\n","                \n","                output = C(data)\n","                real_label = label_onehot.to(device)\n","                errC = criterion(output, real_label)\n","                \n","                errC.backward()\n","                optimizerC.step()\n","                \n","                ###################################################################\n","                # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n","                ###################################################################\n","\n","                # train with real\n","                batch_size = data.shape[0]\n","\n","                D.zero_grad()\n","\n","                real_out = D(data)\n","\n","                real_label = torch.ones(batch_size).to(device)  \n","                fake_label = torch.zeros(batch_size).to(device)  \n","\n","                real_data_score = real_out.mean().item()\n","\n","                # train with fake, taking the noise vector z as the input of D network\n","                z = torch.randn(batch_size, nz+10).to(device)\n","                fake_data = vae.decoder(z)\n","                fake_out = D(fake_data)\n","\n","                # fake_data_score用来输出查看的，是虚假照片的评分，0最假，1为真\n","                fake_data_score = fake_out.mean().item()\n","\n","                d_loss = torch.mean(fake_out) - torch.mean(real_out)               \n","                d_loss.backward()\n","                optimizerD.step()\n","\n","                for layer in D.dis:\n","                  if (layer.__class__.__name__ == 'Linear'):\n","                      layer.weight.requires_grad = False\n","                      layer.weight.clamp_(-c, c)\n","                      layer.weight.requires_grad = True\n","\n","            ###################################################\n","            # (2) Update G network which is the decoder of VAE\n","            ###################################################\n","            z,mean,logstd = vae.encoder(data)\n","            z = torch.cat([z,label_onehot],1)\n","            recon_data = vae.decoder(z)\n","            \n","            vae.zero_grad()\n","            \n","            vae_loss = loss_function(recon_data,data,mean,logstd)\n","\n","            vae_loss.backward(retain_graph=True)\n","            optimizerVAE.step()\n","            \n","            ###############################################\n","            # (3) Update G network: maximize log(D(G(z)))\n","            ###############################################\n","            z,mean,logstd = vae.encoder(data)\n","            z = torch.cat([z,label_onehot],1)\n","            recon_data = vae.decoder(z)\n","            \n","            vae.zero_grad()\n","\n","            # real_label = torch.ones(batch_size).to(device)  \n","            output = D(recon_data)\n","            errVAE = torch.mean(-output)\n","\n","            errVAE.backward()\n","            optimizerVAE.step()\n","\n","            ###############################################\n","            # (4) Update C network\n","            ###############################################   \n","            z,mean,logstd = vae.encoder(data)\n","            z = torch.cat([z,label_onehot],1)\n","            recon_data = vae.decoder(z) \n","\n","            vae.zero_grad()\n","\n","            output = C(recon_data)\n","            real_label = label_onehot\n","            vae_loss3 = criterion(output, real_label)\n","         \n","            vae_loss3.backward()\n","            optimizerVAE.step()\n","\n","        epoch_end_time = time.time()\n","        per_epoch_ptime = epoch_end_time - epoch_start_time\n","        print('[%d/%d] time: %.2f real_score: %.4f fake_score: %.4f '\n","              % (epoch+1, nepoch, per_epoch_ptime,real_data_score,fake_data_score,))\n","    \n","        sample = torch.randn(100, nz).to(device)\n","        sample = torch.cat([sample,specific_label],1)\n","        output = vae.decoder(sample)\n","        fake_images = make_grid(output.cpu(), nrow=10, normalize=False).detach()\n","        save_image(fake_images, './img_CVAE-WGAN/fake_images-{}.png'.format(epoch + 1))\n","\n","        if(epoch%10==0 and epoch!=0):\n","          !cp -r /content/img_CVAE-WGAN/ /content/drive/MyDrive\n","          \n","    end_time = time.time()\n","    total_time = end_time - start_time\n","    print(\"total time: %.2f \" % total_time )\n","\n","images = []\n","for e in range(nepoch):\n","    img_name = './img_CVAE-WGAN/fake_images-' + str(e+1) + '.png'\n","    images.append(imageio.imread(img_name))\n","imageio.mimsave('./generation_animation.gif', images, fps=2)\n","\n","# torch.save(vae.state_dict(), './CVAE-WGANGP-VAE.pth')\n","# torch.save(D.state_dict(),'./CVAE-WGANGP-Discriminator.pth')"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","=====> Initialization\n","=====> Begin training\n","[1/200] time: 77.58 real_score: 0.7499 fake_score: 0.7469 \n","[2/200] time: 80.86 real_score: 0.0677 fake_score: 0.0357 \n","[3/200] time: 80.10 real_score: 0.6751 fake_score: 0.5915 \n","[4/200] time: 79.98 real_score: 0.5018 fake_score: 0.1424 \n","[5/200] time: 79.97 real_score: 0.6490 fake_score: 0.2344 \n","[6/200] time: 79.90 real_score: 0.1209 fake_score: 0.0250 \n","[7/200] time: 79.88 real_score: 0.5099 fake_score: 0.1198 \n","[8/200] time: 79.88 real_score: 0.6208 fake_score: 0.1619 \n","[9/200] time: 79.89 real_score: 0.9070 fake_score: 0.4438 \n","[10/200] time: 79.91 real_score: 0.7572 fake_score: 0.1133 \n","[11/200] time: 79.90 real_score: 0.9321 fake_score: 0.1933 \n","[12/200] time: 79.90 real_score: 0.7207 fake_score: 0.0334 \n","[13/200] time: 79.87 real_score: 0.9097 fake_score: 0.0963 \n","[14/200] time: 79.93 real_score: 0.8032 fake_score: 0.0409 \n","[15/200] time: 79.96 real_score: 0.8771 fake_score: 0.0948 \n","[16/200] time: 79.87 real_score: 0.9407 fake_score: 0.0802 \n","[17/200] time: 79.99 real_score: 0.8435 fake_score: 0.0529 \n","[18/200] time: 79.94 real_score: 0.9003 fake_score: 0.1120 \n","[19/200] time: 79.85 real_score: 0.7546 fake_score: 0.0295 \n","[20/200] time: 79.90 real_score: 0.9214 fake_score: 0.0904 \n","[21/200] time: 79.92 real_score: 0.9325 fake_score: 0.0617 \n","[22/200] time: 79.86 real_score: 0.9000 fake_score: 0.0607 \n","[23/200] time: 79.83 real_score: 0.8981 fake_score: 0.1056 \n","[24/200] time: 79.93 real_score: 0.9502 fake_score: 0.0835 \n","[25/200] time: 79.86 real_score: 0.9418 fake_score: 0.0753 \n","[26/200] time: 79.89 real_score: 0.9061 fake_score: 0.0107 \n","[27/200] time: 79.86 real_score: 0.9688 fake_score: 0.1460 \n","[28/200] time: 79.80 real_score: 0.9903 fake_score: 0.2423 \n","[29/200] time: 79.80 real_score: 0.9860 fake_score: 0.1599 \n","[30/200] time: 79.84 real_score: 0.9065 fake_score: 0.0741 \n","[31/200] time: 79.83 real_score: 0.9481 fake_score: 0.0411 \n","[32/200] time: 79.73 real_score: 0.8665 fake_score: 0.0425 \n","[33/200] time: 79.75 real_score: 0.9779 fake_score: 0.0728 \n","[34/200] time: 79.73 real_score: 0.9605 fake_score: 0.1269 \n","[35/200] time: 79.78 real_score: 0.9855 fake_score: 0.0736 \n","[36/200] time: 79.72 real_score: 0.9982 fake_score: 0.1189 \n","[37/200] time: 79.75 real_score: 0.9746 fake_score: 0.0692 \n","[38/200] time: 79.78 real_score: 0.9995 fake_score: 0.2541 \n","[39/200] time: 79.78 real_score: 0.9775 fake_score: 0.1020 \n","[40/200] time: 79.77 real_score: 0.9269 fake_score: 0.0650 \n","[41/200] time: 79.78 real_score: 0.9892 fake_score: 0.0389 \n","[42/200] time: 79.66 real_score: 0.9910 fake_score: 0.1461 \n","[43/200] time: 79.70 real_score: 0.9489 fake_score: 0.0623 \n","[44/200] time: 79.73 real_score: 0.9856 fake_score: 0.1145 \n","[45/200] time: 79.75 real_score: 0.9920 fake_score: 0.1078 \n","[46/200] time: 79.73 real_score: 0.9690 fake_score: 0.0649 \n","[47/200] time: 79.81 real_score: 0.9412 fake_score: 0.0297 \n","[48/200] time: 79.73 real_score: 0.9955 fake_score: 0.0521 \n","[49/200] time: 79.75 real_score: 0.9900 fake_score: 0.0840 \n","[50/200] time: 79.69 real_score: 0.9680 fake_score: 0.0500 \n","[51/200] time: 79.74 real_score: 0.9842 fake_score: 0.0404 \n","[52/200] time: 79.70 real_score: 0.9924 fake_score: 0.0370 \n","[53/200] time: 79.69 real_score: 0.9051 fake_score: 0.0471 \n","[54/200] time: 79.74 real_score: 0.9602 fake_score: 0.0143 \n","[55/200] time: 79.73 real_score: 0.9849 fake_score: 0.0447 \n","[56/200] time: 79.64 real_score: 0.9877 fake_score: 0.0163 \n","[57/200] time: 79.78 real_score: 0.9870 fake_score: 0.0098 \n","[58/200] time: 80.61 real_score: 0.9921 fake_score: 0.0647 \n","[59/200] time: 80.72 real_score: 0.9885 fake_score: 0.0771 \n","[60/200] time: 80.46 real_score: 0.9982 fake_score: 0.0357 \n","[61/200] time: 80.06 real_score: 0.9557 fake_score: 0.0376 \n","[62/200] time: 79.93 real_score: 0.9955 fake_score: 0.0704 \n","[63/200] time: 79.73 real_score: 0.9866 fake_score: 0.0309 \n","[64/200] time: 79.75 real_score: 0.9970 fake_score: 0.0487 \n","[65/200] time: 79.83 real_score: 0.9970 fake_score: 0.0016 \n","[66/200] time: 79.73 real_score: 0.9877 fake_score: 0.0294 \n","[67/200] time: 79.84 real_score: 0.9972 fake_score: 0.0699 \n","[68/200] time: 79.72 real_score: 0.9973 fake_score: 0.0494 \n","[69/200] time: 79.76 real_score: 0.9856 fake_score: 0.0553 \n","[70/200] time: 79.80 real_score: 0.9916 fake_score: 0.0210 \n","[71/200] time: 79.66 real_score: 0.9915 fake_score: 0.0697 \n","[72/200] time: 79.81 real_score: 0.9844 fake_score: 0.0377 \n","[73/200] time: 79.67 real_score: 0.9972 fake_score: 0.0263 \n","[74/200] time: 79.70 real_score: 0.9863 fake_score: 0.0586 \n","[75/200] time: 79.63 real_score: 0.9990 fake_score: 0.1034 \n","[76/200] time: 79.79 real_score: 0.9874 fake_score: 0.0227 \n","[77/200] time: 79.63 real_score: 0.9871 fake_score: 0.0200 \n","[78/200] time: 79.77 real_score: 0.9921 fake_score: 0.0493 \n","[79/200] time: 79.66 real_score: 0.9955 fake_score: 0.0258 \n","[80/200] time: 79.65 real_score: 0.9945 fake_score: 0.0352 \n","[81/200] time: 79.67 real_score: 0.9844 fake_score: 0.0054 \n","[82/200] time: 79.56 real_score: 0.9970 fake_score: 0.0274 \n","[83/200] time: 79.67 real_score: 0.9994 fake_score: 0.0264 \n","[84/200] time: 79.62 real_score: 0.9981 fake_score: 0.0226 \n","[85/200] time: 79.63 real_score: 0.9944 fake_score: 0.0173 \n","[86/200] time: 79.73 real_score: 0.9876 fake_score: 0.0116 \n","[87/200] time: 79.70 real_score: 0.9970 fake_score: 0.0151 \n","[88/200] time: 79.61 real_score: 0.9991 fake_score: 0.0247 \n","[89/200] time: 79.71 real_score: 0.9990 fake_score: 0.0224 \n","[90/200] time: 79.67 real_score: 0.9723 fake_score: 0.0101 \n","[91/200] time: 79.65 real_score: 0.9901 fake_score: 0.0324 \n","[92/200] time: 79.68 real_score: 0.9990 fake_score: 0.0689 \n","[93/200] time: 79.63 real_score: 0.9973 fake_score: 0.0224 \n","[94/200] time: 79.68 real_score: 0.9948 fake_score: 0.0171 \n","[95/200] time: 79.62 real_score: 0.9979 fake_score: 0.0275 \n","[96/200] time: 79.65 real_score: 0.9974 fake_score: 0.0350 \n","[97/200] time: 79.75 real_score: 0.9962 fake_score: 0.0003 \n","[98/200] time: 79.69 real_score: 0.9998 fake_score: 0.0308 \n","[99/200] time: 79.73 real_score: 0.9936 fake_score: 0.0373 \n","[100/200] time: 79.64 real_score: 0.9730 fake_score: 0.0049 \n","[101/200] time: 79.71 real_score: 0.9993 fake_score: 0.0070 \n","[102/200] time: 79.62 real_score: 0.9961 fake_score: 0.0267 \n","[103/200] time: 79.73 real_score: 0.9968 fake_score: 0.0306 \n","[104/200] time: 79.72 real_score: 0.9878 fake_score: 0.0159 \n","[105/200] time: 79.67 real_score: 0.9954 fake_score: 0.0015 \n","[106/200] time: 79.56 real_score: 0.9878 fake_score: 0.0453 \n","[107/200] time: 79.53 real_score: 0.9894 fake_score: 0.0160 \n","[108/200] time: 79.61 real_score: 0.9882 fake_score: 0.0041 \n","[109/200] time: 79.58 real_score: 0.9995 fake_score: 0.0269 \n","[110/200] time: 79.56 real_score: 0.9823 fake_score: 0.0006 \n","[111/200] time: 79.56 real_score: 0.9993 fake_score: 0.0182 \n","[112/200] time: 79.57 real_score: 0.9986 fake_score: 0.0176 \n","[113/200] time: 79.63 real_score: 0.9862 fake_score: 0.0315 \n","[114/200] time: 79.80 real_score: 0.9911 fake_score: 0.0008 \n","[115/200] time: 81.02 real_score: 0.9970 fake_score: 0.0124 \n","[116/200] time: 80.65 real_score: 0.9976 fake_score: 0.0230 \n","[117/200] time: 80.03 real_score: 0.9970 fake_score: 0.0398 \n","[118/200] time: 79.76 real_score: 0.9966 fake_score: 0.0278 \n","[119/200] time: 79.65 real_score: 0.9986 fake_score: 0.0251 \n","[120/200] time: 79.60 real_score: 0.9916 fake_score: 0.0361 \n","[121/200] time: 79.55 real_score: 0.9997 fake_score: 0.0395 \n","[122/200] time: 79.50 real_score: 0.9988 fake_score: 0.0261 \n","[123/200] time: 79.55 real_score: 0.9721 fake_score: 0.0050 \n","[124/200] time: 79.56 real_score: 0.9996 fake_score: 0.0246 \n","[125/200] time: 79.58 real_score: 0.9988 fake_score: 0.0141 \n","[126/200] time: 79.60 real_score: 0.9993 fake_score: 0.0243 \n","[127/200] time: 79.47 real_score: 0.9933 fake_score: 0.0123 \n","[128/200] time: 79.66 real_score: 0.9873 fake_score: 0.0271 \n","[129/200] time: 79.55 real_score: 0.9993 fake_score: 0.0743 \n","[130/200] time: 79.56 real_score: 0.9987 fake_score: 0.0114 \n","[131/200] time: 79.62 real_score: 0.9724 fake_score: 0.0321 \n","[132/200] time: 79.54 real_score: 0.9887 fake_score: 0.0114 \n","[133/200] time: 79.53 real_score: 0.9833 fake_score: 0.0000 \n","[134/200] time: 79.50 real_score: 0.9986 fake_score: 0.0029 \n","[135/200] time: 79.50 real_score: 0.9982 fake_score: 0.0090 \n","[136/200] time: 79.53 real_score: 0.9845 fake_score: 0.0263 \n","[137/200] time: 79.62 real_score: 0.9921 fake_score: 0.0125 \n","[138/200] time: 79.58 real_score: 0.9982 fake_score: 0.0174 \n","[139/200] time: 79.56 real_score: 1.0000 fake_score: 0.0628 \n","[140/200] time: 79.61 real_score: 0.9993 fake_score: 0.0283 \n","[141/200] time: 79.63 real_score: 0.9999 fake_score: 0.0389 \n","[142/200] time: 79.63 real_score: 0.9766 fake_score: 0.0129 \n","[143/200] time: 79.54 real_score: 0.9956 fake_score: 0.0139 \n","[144/200] time: 79.52 real_score: 0.9997 fake_score: 0.0551 \n","[145/200] time: 79.50 real_score: 0.9943 fake_score: 0.0155 \n","[146/200] time: 79.53 real_score: 0.9964 fake_score: 0.0335 \n","[147/200] time: 79.56 real_score: 0.9856 fake_score: 0.0337 \n","[148/200] time: 79.60 real_score: 0.9990 fake_score: 0.0001 \n","[149/200] time: 79.53 real_score: 0.9954 fake_score: 0.0147 \n","[150/200] time: 79.54 real_score: 0.9971 fake_score: 0.0127 \n","[151/200] time: 79.55 real_score: 0.9991 fake_score: 0.0130 \n","[152/200] time: 79.49 real_score: 0.9923 fake_score: 0.0134 \n","[153/200] time: 79.51 real_score: 0.9966 fake_score: 0.0002 \n","[154/200] time: 79.53 real_score: 0.9977 fake_score: 0.0120 \n","[155/200] time: 79.54 real_score: 1.0000 fake_score: 0.0401 \n","[156/200] time: 79.52 real_score: 0.9881 fake_score: 0.0002 \n","[157/200] time: 79.46 real_score: 0.9995 fake_score: 0.0174 \n","[158/200] time: 79.44 real_score: 0.9990 fake_score: 0.0088 \n","[159/200] time: 79.45 real_score: 0.9906 fake_score: 0.0237 \n","[160/200] time: 79.47 real_score: 0.9864 fake_score: 0.0065 \n","[161/200] time: 79.43 real_score: 0.9835 fake_score: 0.0034 \n","[162/200] time: 79.47 real_score: 0.9994 fake_score: 0.0165 \n","[163/200] time: 79.50 real_score: 0.9981 fake_score: 0.0367 \n","[164/200] time: 79.47 real_score: 0.9951 fake_score: 0.0245 \n","[165/200] time: 79.41 real_score: 0.9812 fake_score: 0.0249 \n","[166/200] time: 79.49 real_score: 0.9806 fake_score: 0.0012 \n","[167/200] time: 79.48 real_score: 1.0000 fake_score: 0.0122 \n","[168/200] time: 79.42 real_score: 0.9993 fake_score: 0.0272 \n","[169/200] time: 79.53 real_score: 0.9937 fake_score: 0.0103 \n","[170/200] time: 79.49 real_score: 0.9963 fake_score: 0.0042 \n","[171/200] time: 80.28 real_score: 0.9999 fake_score: 0.0120 \n","[172/200] time: 80.69 real_score: 0.9988 fake_score: 0.0009 \n","[173/200] time: 80.36 real_score: 0.9754 fake_score: 0.0191 \n","[174/200] time: 79.96 real_score: 1.0000 fake_score: 0.0164 \n","[175/200] time: 79.84 real_score: 0.9993 fake_score: 0.0124 \n","[176/200] time: 79.61 real_score: 0.9965 fake_score: 0.0264 \n","[177/200] time: 79.58 real_score: 0.9999 fake_score: 0.0160 \n","[178/200] time: 79.58 real_score: 0.9916 fake_score: 0.0001 \n","[179/200] time: 79.55 real_score: 0.9998 fake_score: 0.0084 \n","[180/200] time: 79.58 real_score: 0.9995 fake_score: 0.0014 \n","[181/200] time: 79.58 real_score: 0.9976 fake_score: 0.0521 \n","[182/200] time: 79.52 real_score: 0.9994 fake_score: 0.0021 \n","[183/200] time: 79.52 real_score: 0.9996 fake_score: 0.0051 \n","[184/200] time: 79.53 real_score: 0.9948 fake_score: 0.0001 \n","[185/200] time: 79.51 real_score: 0.9983 fake_score: 0.0143 \n","[186/200] time: 79.58 real_score: 1.0000 fake_score: 0.0220 \n","[187/200] time: 79.46 real_score: 0.9889 fake_score: 0.0173 \n","[188/200] time: 79.44 real_score: 0.9992 fake_score: 0.0125 \n","[189/200] time: 79.57 real_score: 0.9939 fake_score: 0.0309 \n","[190/200] time: 79.61 real_score: 0.9997 fake_score: 0.0101 \n","[191/200] time: 79.48 real_score: 0.9846 fake_score: 0.0001 \n","[192/200] time: 79.40 real_score: 1.0000 fake_score: 0.0231 \n","[193/200] time: 79.43 real_score: 0.9988 fake_score: 0.0294 \n","[194/200] time: 79.48 real_score: 0.9976 fake_score: 0.0248 \n","[195/200] time: 79.63 real_score: 1.0000 fake_score: 0.0065 \n","[196/200] time: 79.51 real_score: 0.9938 fake_score: 0.0001 \n","[197/200] time: 79.58 real_score: 0.9999 fake_score: 0.0022 \n","[198/200] time: 79.57 real_score: 0.9868 fake_score: 0.0124 \n","[199/200] time: 79.54 real_score: 0.9695 fake_score: 0.0000 \n","[200/200] time: 79.50 real_score: 0.9997 fake_score: 0.0265 \n","total time: 15961.88 \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3Svdpi55FgsD","executionInfo":{"status":"ok","timestamp":1606574646535,"user_tz":-480,"elapsed":1805,"user":{"displayName":"韩轶凡","photoUrl":"","userId":"03071036090357054572"}}},"source":["!cp -r /content/img_CVAE-WGAN/ /content/drive/MyDrive\n","!cp -r /content/generation_animation.gif /content/drive/MyDrive"],"execution_count":26,"outputs":[]}]}